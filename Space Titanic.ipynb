{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4aa9d2",
   "metadata": {},
   "source": [
    "Importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1051347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f396b",
   "metadata": {},
   "source": [
    "Reading the dataset as input, and splitting the \"Cabin\" feature into three separate features, ensuring that \"Transported\" feature is at the last, (Change the directory location as required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b44cbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"C:/Users/soume/OneDrive/Desktop/Space Titanic/train.csv\")\n",
    "dataset[[\"Deck\", \"Cabin_num\", \"Side\"]] = dataset[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "cols_at_end = ['Transported']\n",
    "dataset = dataset[[c for c in dataset if c not in cols_at_end] \n",
    "        + [c for c in cols_at_end if c in dataset]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6356316d",
   "metadata": {},
   "source": [
    "Storing the dependent and independent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca569727",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Cabin', axis=1)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c4980",
   "metadata": {},
   "source": [
    "Using Simple Imputer to replace the missing values in categrorical features with the most frequent values, and dropping the \"Name\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52583f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer1 = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "imputer1.fit(X[:, [1, 2, 3, 4, 6, 12, 14]])\n",
    "X[:, [1, 2, 3, 4, 6, 12, 14]] = imputer1.transform(X[:, [1, 2, 3, 4, 6, 12, 14]])\n",
    "X = np.delete(X, 11, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c27f94",
   "metadata": {},
   "source": [
    "Converting the values in \"Cabin_num\" from string to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16eaf3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(X)):\n",
    "    X[x][12] = float(X[x][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf2bc65",
   "metadata": {},
   "source": [
    "Using Simple Imputer to replace the missing values in numerical features with their mean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56e7a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer2 = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imputer2.fit(X[:, [4,6,7,8,9,10,12]])\n",
    "X[:,[4,6,7,8,9,10,12]]  = imputer2.transform(X[:, [4,6,7,8,9,10,12]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09be86ba",
   "metadata": {},
   "source": [
    "Using Label Encoder to apply label encoding on \"Cryo\" and \"VIP\" features, and removing the original versions of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dd23a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "Cryo = X[:, 2]\n",
    "VIP = X[:, 5]\n",
    "Cryo = le1.fit_transform(Cryo)\n",
    "VIP  = le2.fit_transform(VIP)\n",
    "Cryo = Cryo.reshape(len(Cryo), 1)\n",
    "VIP = VIP.reshape(len(VIP), 1)\n",
    "X = np.hstack((X, Cryo))\n",
    "X = np.hstack((X, VIP))\n",
    "X = np.delete(X, 2, 1)\n",
    "X = np.delete(X, 4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9239d7",
   "metadata": {},
   "source": [
    "Removing the \"PassengerID\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06d39b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64eacd9",
   "metadata": {},
   "source": [
    "Using OneHotEncoder to apply One Hot Encoding on \"HomePlanet\" and \"Destination\" features, and avoiding the dummy variable trap by removing one dummy variable for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "825a7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct1 = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "X = np.array(ct1.fit_transform(X))\n",
    "X = np.delete(X, 0, 1)\n",
    "ct2 = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [2])], remainder = 'passthrough')\n",
    "X = np.array(ct2.fit_transform(X))\n",
    "X = np.delete(X, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b6c56",
   "metadata": {},
   "source": [
    "Applying Label Encoding on the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea0764d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2e146",
   "metadata": {},
   "source": [
    "Applying Label Encoding on \"Side\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "059a727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Side = X[:, 12]\n",
    "Side = le3.fit_transform(Side)\n",
    "Side = Side.reshape(len(Side), 1)\n",
    "X = np.hstack((X, Side))\n",
    "X = np.delete(X, 12, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf90e08",
   "metadata": {},
   "source": [
    "Applying One Hot Encoding on \"Deck\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c5695ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct3 = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [10])], remainder = 'passthrough')\n",
    "X = np.array(ct3.fit_transform(X))\n",
    "X = np.delete(X, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a5f5ca",
   "metadata": {},
   "source": [
    "Applying standardisation on independent features using Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2820195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48adfec0",
   "metadata": {},
   "source": [
    "Creating and training an ANN on input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "634bed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "272/272 [==============================] - 1s 723us/step - loss: 0.5834 - accuracy: 0.7187\n",
      "Epoch 2/110\n",
      "272/272 [==============================] - 0s 743us/step - loss: 0.4714 - accuracy: 0.7913\n",
      "Epoch 3/110\n",
      "272/272 [==============================] - 0s 755us/step - loss: 0.4537 - accuracy: 0.7943\n",
      "Epoch 4/110\n",
      "272/272 [==============================] - 0s 747us/step - loss: 0.4427 - accuracy: 0.7997\n",
      "Epoch 5/110\n",
      "272/272 [==============================] - 0s 719us/step - loss: 0.4363 - accuracy: 0.8018\n",
      "Epoch 6/110\n",
      "272/272 [==============================] - 0s 700us/step - loss: 0.4310 - accuracy: 0.8008\n",
      "Epoch 7/110\n",
      "272/272 [==============================] - 0s 718us/step - loss: 0.4272 - accuracy: 0.8033\n",
      "Epoch 8/110\n",
      "272/272 [==============================] - 0s 727us/step - loss: 0.4235 - accuracy: 0.8017\n",
      "Epoch 9/110\n",
      "272/272 [==============================] - 0s 786us/step - loss: 0.4214 - accuracy: 0.8024\n",
      "Epoch 10/110\n",
      "272/272 [==============================] - 0s 693us/step - loss: 0.4187 - accuracy: 0.8027\n",
      "Epoch 11/110\n",
      "272/272 [==============================] - 0s 718us/step - loss: 0.4166 - accuracy: 0.8020\n",
      "Epoch 12/110\n",
      "272/272 [==============================] - 0s 729us/step - loss: 0.4150 - accuracy: 0.8046\n",
      "Epoch 13/110\n",
      "272/272 [==============================] - 0s 725us/step - loss: 0.4131 - accuracy: 0.8061\n",
      "Epoch 14/110\n",
      "272/272 [==============================] - 0s 721us/step - loss: 0.4113 - accuracy: 0.8051\n",
      "Epoch 15/110\n",
      "272/272 [==============================] - 0s 717us/step - loss: 0.4095 - accuracy: 0.8049\n",
      "Epoch 16/110\n",
      "272/272 [==============================] - 0s 733us/step - loss: 0.4086 - accuracy: 0.8063\n",
      "Epoch 17/110\n",
      "272/272 [==============================] - 0s 757us/step - loss: 0.4070 - accuracy: 0.8043\n",
      "Epoch 18/110\n",
      "272/272 [==============================] - 0s 713us/step - loss: 0.4058 - accuracy: 0.8067\n",
      "Epoch 19/110\n",
      "272/272 [==============================] - 0s 717us/step - loss: 0.4053 - accuracy: 0.8047\n",
      "Epoch 20/110\n",
      "272/272 [==============================] - 0s 769us/step - loss: 0.4048 - accuracy: 0.8084\n",
      "Epoch 21/110\n",
      "272/272 [==============================] - 0s 766us/step - loss: 0.4039 - accuracy: 0.8074\n",
      "Epoch 22/110\n",
      "272/272 [==============================] - 0s 731us/step - loss: 0.4029 - accuracy: 0.8077\n",
      "Epoch 23/110\n",
      "272/272 [==============================] - 0s 752us/step - loss: 0.4027 - accuracy: 0.8077\n",
      "Epoch 24/110\n",
      "272/272 [==============================] - 0s 755us/step - loss: 0.4015 - accuracy: 0.8081\n",
      "Epoch 25/110\n",
      "272/272 [==============================] - 0s 811us/step - loss: 0.4017 - accuracy: 0.8055\n",
      "Epoch 26/110\n",
      "272/272 [==============================] - 0s 876us/step - loss: 0.4011 - accuracy: 0.8085\n",
      "Epoch 27/110\n",
      "272/272 [==============================] - 0s 765us/step - loss: 0.3997 - accuracy: 0.8090\n",
      "Epoch 28/110\n",
      "272/272 [==============================] - 0s 790us/step - loss: 0.3999 - accuracy: 0.8087\n",
      "Epoch 29/110\n",
      "272/272 [==============================] - 0s 692us/step - loss: 0.3981 - accuracy: 0.8069\n",
      "Epoch 30/110\n",
      "272/272 [==============================] - 0s 782us/step - loss: 0.3978 - accuracy: 0.8100\n",
      "Epoch 31/110\n",
      "272/272 [==============================] - 0s 765us/step - loss: 0.3974 - accuracy: 0.8097\n",
      "Epoch 32/110\n",
      "272/272 [==============================] - 0s 725us/step - loss: 0.3974 - accuracy: 0.8089\n",
      "Epoch 33/110\n",
      "272/272 [==============================] - 0s 692us/step - loss: 0.3971 - accuracy: 0.8084\n",
      "Epoch 34/110\n",
      "272/272 [==============================] - 0s 735us/step - loss: 0.3965 - accuracy: 0.8084\n",
      "Epoch 35/110\n",
      "272/272 [==============================] - 0s 717us/step - loss: 0.3968 - accuracy: 0.8082\n",
      "Epoch 36/110\n",
      "272/272 [==============================] - 0s 718us/step - loss: 0.3964 - accuracy: 0.8066\n",
      "Epoch 37/110\n",
      "272/272 [==============================] - 0s 743us/step - loss: 0.3963 - accuracy: 0.8079\n",
      "Epoch 38/110\n",
      "272/272 [==============================] - 0s 795us/step - loss: 0.3956 - accuracy: 0.8095\n",
      "Epoch 39/110\n",
      "272/272 [==============================] - 0s 769us/step - loss: 0.3950 - accuracy: 0.8080\n",
      "Epoch 40/110\n",
      "272/272 [==============================] - 0s 753us/step - loss: 0.3949 - accuracy: 0.8119\n",
      "Epoch 41/110\n",
      "272/272 [==============================] - 0s 802us/step - loss: 0.3947 - accuracy: 0.8067\n",
      "Epoch 42/110\n",
      "272/272 [==============================] - 0s 726us/step - loss: 0.3943 - accuracy: 0.8107\n",
      "Epoch 43/110\n",
      "272/272 [==============================] - 0s 825us/step - loss: 0.3945 - accuracy: 0.8123\n",
      "Epoch 44/110\n",
      "272/272 [==============================] - 0s 838us/step - loss: 0.3932 - accuracy: 0.8110\n",
      "Epoch 45/110\n",
      "272/272 [==============================] - 0s 686us/step - loss: 0.3934 - accuracy: 0.8090\n",
      "Epoch 46/110\n",
      "272/272 [==============================] - 0s 735us/step - loss: 0.3938 - accuracy: 0.8081\n",
      "Epoch 47/110\n",
      "272/272 [==============================] - 0s 994us/step - loss: 0.3923 - accuracy: 0.8101\n",
      "Epoch 48/110\n",
      "272/272 [==============================] - 0s 974us/step - loss: 0.3923 - accuracy: 0.8084\n",
      "Epoch 49/110\n",
      "272/272 [==============================] - 0s 923us/step - loss: 0.3920 - accuracy: 0.8095\n",
      "Epoch 50/110\n",
      "272/272 [==============================] - 0s 728us/step - loss: 0.3914 - accuracy: 0.8090\n",
      "Epoch 51/110\n",
      "272/272 [==============================] - 0s 729us/step - loss: 0.3920 - accuracy: 0.8095\n",
      "Epoch 52/110\n",
      "272/272 [==============================] - 0s 721us/step - loss: 0.3915 - accuracy: 0.8108\n",
      "Epoch 53/110\n",
      "272/272 [==============================] - 0s 707us/step - loss: 0.3913 - accuracy: 0.8107\n",
      "Epoch 54/110\n",
      "272/272 [==============================] - 0s 750us/step - loss: 0.3903 - accuracy: 0.8112\n",
      "Epoch 55/110\n",
      "272/272 [==============================] - 0s 922us/step - loss: 0.3920 - accuracy: 0.8100\n",
      "Epoch 56/110\n",
      "272/272 [==============================] - 0s 972us/step - loss: 0.3909 - accuracy: 0.8096\n",
      "Epoch 57/110\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8098\n",
      "Epoch 58/110\n",
      "272/272 [==============================] - 0s 923us/step - loss: 0.3901 - accuracy: 0.8087\n",
      "Epoch 59/110\n",
      "272/272 [==============================] - 0s 870us/step - loss: 0.3900 - accuracy: 0.8075\n",
      "Epoch 60/110\n",
      "272/272 [==============================] - 0s 864us/step - loss: 0.3892 - accuracy: 0.8111\n",
      "Epoch 61/110\n",
      "272/272 [==============================] - 0s 718us/step - loss: 0.3887 - accuracy: 0.8108\n",
      "Epoch 62/110\n",
      "272/272 [==============================] - 0s 743us/step - loss: 0.3901 - accuracy: 0.8109\n",
      "Epoch 63/110\n",
      "272/272 [==============================] - 0s 740us/step - loss: 0.3883 - accuracy: 0.8115\n",
      "Epoch 64/110\n",
      "272/272 [==============================] - 0s 742us/step - loss: 0.3877 - accuracy: 0.8125\n",
      "Epoch 65/110\n",
      "272/272 [==============================] - 0s 818us/step - loss: 0.3871 - accuracy: 0.8131\n",
      "Epoch 66/110\n",
      "272/272 [==============================] - 0s 737us/step - loss: 0.3881 - accuracy: 0.8120\n",
      "Epoch 67/110\n",
      "272/272 [==============================] - 0s 847us/step - loss: 0.3878 - accuracy: 0.8120\n",
      "Epoch 68/110\n",
      "272/272 [==============================] - 0s 825us/step - loss: 0.3874 - accuracy: 0.8105\n",
      "Epoch 69/110\n",
      "272/272 [==============================] - 0s 797us/step - loss: 0.3875 - accuracy: 0.8093\n",
      "Epoch 70/110\n",
      "272/272 [==============================] - 0s 733us/step - loss: 0.3862 - accuracy: 0.8126\n",
      "Epoch 71/110\n",
      "272/272 [==============================] - 0s 797us/step - loss: 0.3852 - accuracy: 0.8125\n",
      "Epoch 72/110\n",
      "272/272 [==============================] - 0s 851us/step - loss: 0.3852 - accuracy: 0.8128\n",
      "Epoch 73/110\n",
      "272/272 [==============================] - 0s 773us/step - loss: 0.3852 - accuracy: 0.8109\n",
      "Epoch 74/110\n",
      "272/272 [==============================] - 0s 771us/step - loss: 0.3845 - accuracy: 0.8135\n",
      "Epoch 75/110\n",
      "272/272 [==============================] - 0s 777us/step - loss: 0.3848 - accuracy: 0.8127\n",
      "Epoch 76/110\n",
      "272/272 [==============================] - 0s 742us/step - loss: 0.3825 - accuracy: 0.8125\n",
      "Epoch 77/110\n",
      "272/272 [==============================] - 0s 750us/step - loss: 0.3838 - accuracy: 0.8146\n",
      "Epoch 78/110\n",
      "272/272 [==============================] - 0s 788us/step - loss: 0.3836 - accuracy: 0.8133\n",
      "Epoch 79/110\n",
      "272/272 [==============================] - 0s 737us/step - loss: 0.3826 - accuracy: 0.8116\n",
      "Epoch 80/110\n",
      "272/272 [==============================] - 0s 724us/step - loss: 0.3823 - accuracy: 0.8127\n",
      "Epoch 81/110\n",
      "272/272 [==============================] - 0s 773us/step - loss: 0.3819 - accuracy: 0.8107\n",
      "Epoch 82/110\n",
      "272/272 [==============================] - 0s 805us/step - loss: 0.3818 - accuracy: 0.8093\n",
      "Epoch 83/110\n",
      "272/272 [==============================] - 0s 688us/step - loss: 0.3807 - accuracy: 0.8124\n",
      "Epoch 84/110\n",
      "272/272 [==============================] - 0s 754us/step - loss: 0.3814 - accuracy: 0.8128\n",
      "Epoch 85/110\n",
      "272/272 [==============================] - 0s 768us/step - loss: 0.3808 - accuracy: 0.8125\n",
      "Epoch 86/110\n",
      "272/272 [==============================] - 0s 684us/step - loss: 0.3809 - accuracy: 0.8127\n",
      "Epoch 87/110\n",
      "272/272 [==============================] - 0s 897us/step - loss: 0.3809 - accuracy: 0.8123\n",
      "Epoch 88/110\n",
      "272/272 [==============================] - 0s 794us/step - loss: 0.3795 - accuracy: 0.8124\n",
      "Epoch 89/110\n",
      "272/272 [==============================] - 0s 914us/step - loss: 0.3795 - accuracy: 0.8135\n",
      "Epoch 90/110\n",
      "272/272 [==============================] - 0s 858us/step - loss: 0.3788 - accuracy: 0.8125\n",
      "Epoch 91/110\n",
      "272/272 [==============================] - 0s 702us/step - loss: 0.3784 - accuracy: 0.8153\n",
      "Epoch 92/110\n",
      "272/272 [==============================] - 0s 909us/step - loss: 0.3787 - accuracy: 0.8118\n",
      "Epoch 93/110\n",
      "272/272 [==============================] - 0s 758us/step - loss: 0.3779 - accuracy: 0.8142\n",
      "Epoch 94/110\n",
      "272/272 [==============================] - 0s 739us/step - loss: 0.3782 - accuracy: 0.8157\n",
      "Epoch 95/110\n",
      "272/272 [==============================] - 0s 718us/step - loss: 0.3774 - accuracy: 0.8132\n",
      "Epoch 96/110\n",
      "272/272 [==============================] - 0s 803us/step - loss: 0.3779 - accuracy: 0.8135\n",
      "Epoch 97/110\n",
      "272/272 [==============================] - 0s 831us/step - loss: 0.3770 - accuracy: 0.8147\n",
      "Epoch 98/110\n",
      "272/272 [==============================] - 0s 855us/step - loss: 0.3767 - accuracy: 0.8138\n",
      "Epoch 99/110\n",
      "272/272 [==============================] - 0s 821us/step - loss: 0.3766 - accuracy: 0.8163\n",
      "Epoch 100/110\n",
      "272/272 [==============================] - 0s 890us/step - loss: 0.3768 - accuracy: 0.8146\n",
      "Epoch 101/110\n",
      "272/272 [==============================] - 0s 768us/step - loss: 0.3769 - accuracy: 0.8151\n",
      "Epoch 102/110\n",
      "272/272 [==============================] - 0s 881us/step - loss: 0.3773 - accuracy: 0.8153\n",
      "Epoch 103/110\n",
      "272/272 [==============================] - 0s 777us/step - loss: 0.3760 - accuracy: 0.8155\n",
      "Epoch 104/110\n",
      "272/272 [==============================] - 0s 721us/step - loss: 0.3764 - accuracy: 0.8173\n",
      "Epoch 105/110\n",
      "272/272 [==============================] - 0s 892us/step - loss: 0.3757 - accuracy: 0.8154\n",
      "Epoch 106/110\n",
      "272/272 [==============================] - 0s 789us/step - loss: 0.3759 - accuracy: 0.8151\n",
      "Epoch 107/110\n",
      "272/272 [==============================] - 0s 728us/step - loss: 0.3761 - accuracy: 0.8149\n",
      "Epoch 108/110\n",
      "272/272 [==============================] - 0s 770us/step - loss: 0.3756 - accuracy: 0.8188\n",
      "Epoch 109/110\n",
      "272/272 [==============================] - 0s 713us/step - loss: 0.3742 - accuracy: 0.8155\n",
      "Epoch 110/110\n",
      "272/272 [==============================] - 0s 731us/step - loss: 0.3748 - accuracy: 0.8170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2071df33690>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation=\"softsign\"))\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation=\"softsign\"))\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation=\"softsign\"))\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation=\"softsign\"))\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation=\"softsign\"))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "ann.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "ann.fit(X, y, batch_size=32, epochs=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06fde2",
   "metadata": {},
   "source": [
    "Applying the same data preprocessing as above on the test dataset features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0cec34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"C:/Users/soume/OneDrive/Desktop/Space Titanic/test.csv\")\n",
    "dataset[[\"Deck\", \"Cabin_num\", \"Side\"]] = dataset[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "dataset = dataset.drop('Cabin', axis=1)\n",
    "X = dataset.iloc[:, :].values\n",
    "passengerId = X[:, 0]\n",
    "X[:, [1, 2, 3, 4, 6, 12, 14]] = imputer1.transform(X[:, [1, 2, 3, 4, 6, 12, 14]])\n",
    "X = np.delete(X, 11, 1)\n",
    "for x in range(0, len(X)):\n",
    "    X[x][12] = float(X[x][12])\n",
    "X[:,[4,6,7,8,9,10,12]]  = imputer2.transform(X[:, [4,6,7,8,9,10,12]])\n",
    "Cryo = X[:, 2]\n",
    "VIP = X[:, 5]\n",
    "Cryo = le1.transform(Cryo)\n",
    "VIP  = le2.transform(VIP)\n",
    "Cryo = Cryo.reshape(len(Cryo), 1)\n",
    "VIP = VIP.reshape(len(VIP), 1)\n",
    "X = np.hstack((X, Cryo))\n",
    "X = np.hstack((X, VIP))\n",
    "X = np.delete(X, 2, 1)\n",
    "X = np.delete(X, 4, 1)\n",
    "X = np.delete(X, 0, 1)\n",
    "X = np.array(ct1.transform(X))\n",
    "X = np.delete(X, 0, 1)\n",
    "X = np.array(ct2.transform(X))\n",
    "X = np.delete(X, 0, 1)\n",
    "Deck = X[:, 12]\n",
    "Deck = le3.transform(Deck)\n",
    "Deck = Deck.reshape(len(Deck), 1)\n",
    "X = np.hstack((X, Deck))\n",
    "X = np.delete(X, 12, 1)\n",
    "X = np.array(ct3.transform(X))\n",
    "X = np.delete(X, 0, 1)\n",
    "X = sc.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308d9f5",
   "metadata": {},
   "source": [
    "Using the ANN to predict target feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cba5a32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 557us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X)\n",
    "y_pred = (y_pred>0.5)\n",
    "y = np.empty(len(y_pred), dtype=object)\n",
    "for x in range(0, len(y_pred)):\n",
    "    if y_pred[x]==1:\n",
    "        y[x] = \"True\"\n",
    "    else:\n",
    "        y[x] = \"False\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b038242",
   "metadata": {},
   "source": [
    "Creating a new csv file containing predictions, (Change the directory location as required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2054a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1=pd.DataFrame(passengerId)\n",
    "dataframe2=pd.DataFrame(y)\n",
    "dataframe3=pd.concat([dataframe1,dataframe2],axis=1)\n",
    "dataframe3.columns=['PassengerId','Transported']\n",
    "dataframe3.to_csv(\"C:/Users/soume/OneDrive/Desktop/Space Titanic/titanic_ans1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
